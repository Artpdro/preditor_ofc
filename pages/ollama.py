import ollama
import pandas as pd
import json

def carregar_dados():
    try:
        df = pd.read_json('/datatran_consolidado.json', encoding='latin1')
        return df.head(100)  # Amostra pequena para exemplo
    except Exception as e:
        print(f"Erro ao carregar dados: {e}")
        return pd.DataFrame()

def analyze_with_llm(data_summary, question):
    """
    Analisa dados usando Llama 3.1 via Ollama
    
    Args:
        data_summary (str): Resumo dos dados
        question (str): Pergunta a ser respondida
    
    Returns:
        str: Resposta da LLM
    """
    try:
        prompt = f"""
        Voc√™ √© um especialista em an√°lise de dados de tr√¢nsito e seguran√ßa vi√°ria.
        
        Dados dispon√≠veis:
        {data_summary}
        
        Pergunta: {question}
        
        Por favor, forne√ßa uma an√°lise detalhada e insights baseados nos dados apresentados.
        Seja espec√≠fico e mencione padr√µes, tend√™ncias e recomenda√ß√µes pr√°ticas.
        """
        
        response = ollama.chat(
            model='llama3.1',
            messages=[
                {
                    'role': 'user',
                    'content': prompt
                }
            ]
        )
        
        return response['message']['content']
        
    except Exception as e:
        return f"Erro ao conectar com Ollama: {e}"

def calcular_periodo(df):
    """Calcula o per√≠odo de tempo dos dados a partir da coluna 'data_inversa'."""
    if 'data_inversa' not in df.columns:
        return "Per√≠odo n√£o dispon√≠vel"
    try:
        # Converte a coluna para datetime sem modificar o DataFrame original
        datas = pd.to_datetime(df['data_inversa'], format='%d/%m/%Y', errors='coerce').dropna()
        
        if datas.empty:
            return "Per√≠odo n√£o dispon√≠vel"
            
        data_min = datas.min().strftime('%d/%m/%Y')
        data_max = datas.max().strftime('%d/%m/%Y')
        
        return f"{data_min} a {data_max}"
    except Exception:
        return "Erro ao calcular per√≠odo"

def generate_data_summary(df):
    """Gera um resumo dos dados para a LLM"""
    if df.empty:
        return "Nenhum dado dispon√≠vel"
    
    summary = {
        "total_registros": len(df),
        "periodo": calcular_periodo(df),
        "municipios_com_mais_acidentes": df['municipio'].value_counts().head(5).to_dict(),
        "ufs_com_mais_acidentes": df['uf'].value_counts().head(5).to_dict(),
        "tipos_acidente": df['tipo_acidente'].value_counts().to_dict(),
        "condicoes_meteorologicas": df['condicao_metereologica'].value_counts().to_dict()
    }
    
    return json.dumps(summary, indent=2, ensure_ascii=False)

def main():
    """Fun√ß√£o principal do exemplo"""
    print("üöó Exemplo de An√°lise de Acidentes com Llama 3.1")
    print("=" * 50)
    
    # Carregar dados
    print("üìä Carregando dados...")
    df = carregar_dados()
    
    if df.empty:
        print("‚ùå N√£o foi poss√≠vel carregar os dados.")
        return
    
    # Gerar resumo dos dados
    data_summary = generate_data_summary(df)
    print(f"‚úÖ Dados carregados: {len(df)} registros")
    print("\nüìã Resumo dos dados:")
    print(data_summary)
    
    # Perguntas de exemplo
    questions = [
        "Qual o tipo de acidente mais comum e em qual UF ele ocorre com maior frequ√™ncia?",
        "Existe uma rela√ß√£o entre a condi√ß√£o meteorol√≥gica e o tipo de acidente mais comum?",
        "Quais s√£o os 5 munic√≠pios com maior n√∫mero de acidentes e quais s√£o os tipos de acidentes predominantes neles?",
        "Qual a m√©dia de acidentes por dia da semana e qual dia apresenta o maior pico?",
        "Quais recomenda√ß√µes de seguran√ßa vi√°ria podem ser feitas com base nos dados de acidentes?"
    ]
    
    print("\nü§ñ An√°lises com Llama 3.1:")
    print("=" * 50)
    
    for i, question in enumerate(questions, 1):
        print(f"\n{i}. {question}")
        print("-" * 60)
        
        response = analyze_with_llm(data_summary, question)
        print(response)
        print("\n" + "="*60)

def interactive_mode():
    """Modo interativo para perguntas personalizadas"""
    print("\nüîÑ Modo Interativo")
    print("Digite suas perguntas (ou 'sair' para terminar):")
    
    df = carregar_dados()
    if df.empty:
        print("‚ùå N√£o foi poss√≠vel carregar os dados.")
        return
    
    data_summary = generate_data_summary(df)
    
    while True:
        question = input("\n‚ùì Sua pergunta: ").strip()
        
        if question.lower() in ['sair', 'exit', 'quit']:
            print("üëã At√© logo!")
            break
        
        if not question:
            continue
        
        print("\nü§ñ Analisando...")
        response = analyze_with_llm(data_summary, question)
        print(f"\nüí° Resposta:\n{response}")

if __name__ == "__main__":
    try:
        # Verificar se Ollama est√° dispon√≠vel
        ollama.list()
        print("‚úÖ Ollama conectado com sucesso!")
        
        # Executar an√°lises autom√°ticas
        main()
        
        # Modo interativo
        interactive_mode()
        
    except Exception as e:
        print(f"‚ùå Erro ao conectar com Ollama: {e}")
        print("\nüìù Instru√ß√µes para configurar Ollama:")
        print("1. Instalar: curl -fsSL https://ollama.ai/install.sh | sh")
        print("2. Iniciar: ollama serve")
        print("3. Baixar modelo: ollama pull llama3.1")
