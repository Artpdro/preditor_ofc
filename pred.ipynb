{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1307a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52467f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_inversa</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>horario</th>\n",
       "      <th>uf</th>\n",
       "      <th>municipio</th>\n",
       "      <th>tipo_acidente</th>\n",
       "      <th>condicao_metereologica</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>05:40:00</td>\n",
       "      <td>PA</td>\n",
       "      <td>SAO FRANCISCO DO PARA</td>\n",
       "      <td>Saida de leito carrocavel</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>-1,3101929</td>\n",
       "      <td>-47,74456398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>MG</td>\n",
       "      <td>UBERABA</td>\n",
       "      <td>Colisao transversal</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>-19,76747537</td>\n",
       "      <td>-47,98725511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>BA</td>\n",
       "      <td>CANUDOS</td>\n",
       "      <td>Saida de leito carrocavel</td>\n",
       "      <td>Nublado</td>\n",
       "      <td>-10,32002103</td>\n",
       "      <td>-39,06425211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>10:08:00</td>\n",
       "      <td>SP</td>\n",
       "      <td>APARECIDA</td>\n",
       "      <td>Colisao traseira</td>\n",
       "      <td>Sol</td>\n",
       "      <td>-22,85651665</td>\n",
       "      <td>-45,23114328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>12:10:00</td>\n",
       "      <td>MG</td>\n",
       "      <td>JUATUBA</td>\n",
       "      <td>Saida de leito carrocavel</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>-19,947864</td>\n",
       "      <td>-44,381226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_inversa    dia_semana   horario  uf              municipio  \\\n",
       "0   01/01/2020  quarta-feira  05:40:00  PA  SAO FRANCISCO DO PARA   \n",
       "1   01/01/2020  quarta-feira  06:00:00  MG                UBERABA   \n",
       "2   01/01/2020  quarta-feira  06:00:00  BA                CANUDOS   \n",
       "3   01/01/2020  quarta-feira  10:08:00  SP              APARECIDA   \n",
       "4   01/01/2020  quarta-feira  12:10:00  MG                JUATUBA   \n",
       "\n",
       "               tipo_acidente condicao_metereologica      latitude  \\\n",
       "0  Saida de leito carrocavel              Ceu Claro    -1,3101929   \n",
       "1        Colisao transversal              Ceu Claro  -19,76747537   \n",
       "2  Saida de leito carrocavel                Nublado  -10,32002103   \n",
       "3           Colisao traseira                    Sol  -22,85651665   \n",
       "4  Saida de leito carrocavel              Ceu Claro    -19,947864   \n",
       "\n",
       "      longitude  \n",
       "0  -47,74456398  \n",
       "1  -47,98725511  \n",
       "2  -39,06425211  \n",
       "3  -45,23114328  \n",
       "4    -44,381226  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('datatran_consolidado.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bb9c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        data  uf             municipio                tipo_acidente  \\\n",
      "0 2020-01-01  AL  MATRIZ DE CAMARAGIBE  Colisao com objeto estatico   \n",
      "1 2020-01-01  AL    UNIAO DOS PALMARES      Atropelamento de Animal   \n",
      "2 2020-01-01  AP        FERREIRA GOMES      Atropelamento de Animal   \n",
      "3 2020-01-01  AP          PORTO GRANDE    Saida de leito carrocavel   \n",
      "4 2020-01-01  BA               CANUDOS    Saida de leito carrocavel   \n",
      "\n",
      "  condicao_metereologica    dia_semana  acidentes  hora_media  \n",
      "0              Ceu Claro  quarta-feira          1         6.0  \n",
      "1                Nublado  quarta-feira          1         2.0  \n",
      "2              Ceu Claro  quarta-feira          1         0.0  \n",
      "3                  Chuva  quarta-feira          1        15.0  \n",
      "4                Nublado  quarta-feira          1         6.0  \n"
     ]
    }
   ],
   "source": [
    "df[\"data\"] = pd.to_datetime(df[\"data_inversa\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df[\"hora\"] = pd.to_datetime(df[\"horario\"], format=\"%H:%M:%S\", errors=\"coerce\").dt.hour\n",
    "\n",
    "# Remover nulos essenciais para a agregação\n",
    "df.dropna(subset=['data', 'hora', 'tipo_acidente', 'uf', 'municipio'], inplace=True)\n",
    "\n",
    "# AGREGACAO CORRIGIDA: Contar acidentes para a combinação única de Data, Local, Tipo e Condição\n",
    "cols_agrupamento = ['data', 'uf', 'municipio', 'tipo_acidente', 'condicao_metereologica', 'dia_semana']\n",
    "df_agg = df.groupby(cols_agrupamento).agg(\n",
    "    acidentes=(\"data\", \"count\"),\n",
    "    hora_media=('hora', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(df_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c708a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros agrupados: 371301\n"
     ]
    }
   ],
   "source": [
    "df_agg[\"dia_semana_num\"] = df_agg[\"data\"].dt.dayofweek\n",
    "df_agg[\"mes\"] = df_agg[\"data\"].dt.month\n",
    "df_agg[\"ano\"] = df_agg[\"data\"].dt.year\n",
    "df_agg[\"dia_do_ano\"] = df_agg[\"data\"].dt.dayofyear\n",
    "df_agg[\"dia_do_mes\"] = df_agg[\"data\"].dt.day\n",
    "\n",
    "print(f\"Total de registros agrupados: {len(df_agg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4056c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'label_encoder_mappings.json' atualizado.\n"
     ]
    }
   ],
   "source": [
    "cat_features = ['uf', 'municipio', 'tipo_acidente', 'condicao_metereologica']\n",
    "mappings = {}\n",
    "\n",
    "# Aplicar LabelEncoder e salvar mapeamento\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    df_agg[col] = le.fit_transform(df_agg[col].astype(str))\n",
    "    mappings[col] = list(le.classes_)\n",
    "    \n",
    "# Garantir sincronia do mapeamento para a interface.py\n",
    "with open('label_encoder_mappings.json', 'w', encoding='utf-8') as f:\n",
    "    mappings['dia_semana'] = sorted(df['dia_semana'].unique().tolist())\n",
    "    json.dump(mappings, f, ensure_ascii=False)\n",
    "print(\"'label_encoder_mappings.json' atualizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ec018fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'uf', 'municipio', 'tipo_acidente', 'condicao_metereologica', \n",
    "    'hora_media', 'dia_semana_num', 'mes', 'ano', 'dia_do_ano', 'dia_do_mes'\n",
    "]\n",
    "\n",
    "X = df_agg[features]\n",
    "y = df_agg['acidentes']\n",
    "\n",
    "# Índices das colunas categóricas para o LightGBM (0 a 3)\n",
    "cat_indices = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b7f5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn, sys\n",
    "#reg = lgb.LGBMRegressor(random_state=30, verbose=-1, objective='poisson')\n",
    "#reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74a0cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada 1/30 -> R²: 0.4096 | RMSE: 0.1282\n",
      "Rodada 2/30 -> R²: 0.4104 | RMSE: 0.1282\n",
      "Rodada 3/30 -> R²: 0.4165 | RMSE: 0.1277\n",
      "Rodada 4/30 -> R²: 0.4016 | RMSE: 0.1333\n",
      "Rodada 5/30 -> R²: 0.4170 | RMSE: 0.1287\n",
      "Rodada 6/30 -> R²: 0.4294 | RMSE: 0.1286\n",
      "Rodada 7/30 -> R²: 0.4227 | RMSE: 0.1278\n",
      "Rodada 8/30 -> R²: 0.4222 | RMSE: 0.1322\n",
      "Rodada 9/30 -> R²: 0.4053 | RMSE: 0.1341\n",
      "Rodada 10/30 -> R²: 0.4153 | RMSE: 0.1334\n",
      "Rodada 11/30 -> R²: 0.4129 | RMSE: 0.1327\n",
      "Rodada 12/30 -> R²: 0.4165 | RMSE: 0.1307\n",
      "Rodada 13/30 -> R²: 0.4186 | RMSE: 0.1317\n",
      "Rodada 14/30 -> R²: 0.3902 | RMSE: 0.1350\n",
      "Rodada 15/30 -> R²: 0.4281 | RMSE: 0.1286\n",
      "Rodada 16/30 -> R²: 0.4104 | RMSE: 0.1313\n",
      "Rodada 17/30 -> R²: 0.4268 | RMSE: 0.1277\n",
      "Rodada 18/30 -> R²: 0.4001 | RMSE: 0.1314\n",
      "Rodada 19/30 -> R²: 0.4026 | RMSE: 0.1307\n",
      "Rodada 20/30 -> R²: 0.4239 | RMSE: 0.1315\n",
      "Rodada 21/30 -> R²: 0.4120 | RMSE: 0.1309\n",
      "Rodada 22/30 -> R²: 0.4024 | RMSE: 0.1321\n",
      "Rodada 23/30 -> R²: 0.4134 | RMSE: 0.1289\n",
      "Rodada 24/30 -> R²: 0.4210 | RMSE: 0.1314\n",
      "Rodada 25/30 -> R²: 0.4116 | RMSE: 0.1332\n",
      "Rodada 26/30 -> R²: 0.3938 | RMSE: 0.1320\n",
      "Rodada 27/30 -> R²: 0.4087 | RMSE: 0.1296\n",
      "Rodada 28/30 -> R²: 0.3999 | RMSE: 0.1315\n",
      "Rodada 29/30 -> R²: 0.4163 | RMSE: 0.1301\n",
      "Rodada 30/30 -> R²: 0.4231 | RMSE: 0.1284\n",
      "----------------------------------------\n",
      "MÉDIA FINAL -> R²: 0.4127 (±0.0099)\n",
      "MÉDIA FINAL -> RMSE: 0.1307\n"
     ]
    }
   ],
   "source": [
    "# Seleciona as features e o target\n",
    "r2_list = []\n",
    "rmse_list = []\n",
    "n_loops = 30\n",
    "\n",
    "for i in range(n_loops):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i*13)\n",
    "    \n",
    "    # --- HIPERPARÂMETROS EXTREMOS PARA MAXIMIZAR R² ---\n",
    "    # Foco: Aprender mais lentamente (LR baixo) e com mais profundidade (N_Estimators alto)\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective='poisson',       \n",
    "        n_estimators=3000,         # Aumento extremo no número de árvores\n",
    "        learning_rate=0.003,       # Diminuição drástica para precisão máxima\n",
    "        num_leaves=80,             # Aumento na complexidade da árvore\n",
    "        max_depth=15,              # Profundidade alta\n",
    "        min_child_samples=10,      # Permite explicar padrões de contagem muito pequena\n",
    "        reg_alpha=0.5,             # Aumento na regularização L1 (Lasso)\n",
    "        reg_lambda=0.5,            # Aumento na regularização L2 (Ridge)\n",
    "        subsample=0.8,             # Amostragem para reduzir variância\n",
    "        colsample_bytree=0.8,      # Amostragem para reduzir variância\n",
    "        random_state=i,\n",
    "        verbose=-1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, categorical_feature=cat_indices)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2_list.append(r2_score(y_test, y_pred))\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    print(f\"Rodada {i+1}/{n_loops} -> R²: {r2_list[-1]:.4f} | RMSE: {rmse_list[-1]:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"MÉDIA FINAL -> R²: {np.mean(r2_list):.4f} (±{np.std(r2_list):.4f})\")\n",
    "print(f\"MÉDIA FINAL -> RMSE: {np.mean(rmse_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeee9d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final salvo em 'preditor.pkl'. ✅\n"
     ]
    }
   ],
   "source": [
    "model_final = lgb.LGBMRegressor(\n",
    "    objective='poisson',\n",
    "    n_estimators=5000, # Número máximo de árvores\n",
    "    learning_rate=0.001, # Taxa de aprendizado mínima para máximo R²\n",
    "    num_leaves=90,\n",
    "    max_depth=20, # Profundidade máxima para complexidade\n",
    "    min_child_samples=10,\n",
    "    reg_alpha=0.6,\n",
    "    reg_lambda=0.6,\n",
    "    random_state=30,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model_final.fit(X, y, categorical_feature=cat_indices)\n",
    "\n",
    "with open('preditor.pkl', 'wb') as f:\n",
    "    pickle.dump(model_final, f)\n",
    "\n",
    "print(f\"Modelo final salvo em 'preditor.pkl'. ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
