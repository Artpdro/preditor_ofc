{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1307a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52467f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando ao MongoDB Atlas e carregando dados da coleção 'safeway'...\n",
      "Dados carregados com sucesso. Total de 380851 registros.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Tenta carregar o .env usando o diretório do script (funciona em scripts normais)\n",
    "    load_dotenv(dotenv_path=Path(__file__).parent / '.env')\n",
    "except NameError:\n",
    "    # Se __file__ não estiver definido (ambiente interativo),\n",
    "    # carrega o .env do diretório de trabalho atual.\n",
    "    load_dotenv(dotenv_path=Path.cwd() / '.env')\n",
    "except Exception:\n",
    "    # Alternativa mais simples: apenas load_dotenv()\n",
    "    load_dotenv()\n",
    "\n",
    "# --- NOVA LÓGICA DE CARREGAMENTO DO MONGODB ATLAS ---\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\")\n",
    "\n",
    "if not all([MONGO_URI, DB_NAME, COLLECTION_NAME]):\n",
    "    print(\"ERRO: Variáveis de ambiente MONGO_URI, DB_NAME ou COLLECTION_NAME não estão configuradas no arquivo .env.\")\n",
    "    df = pd.DataFrame() # Retorna DataFrame vazio em caso de erro\n",
    "else:\n",
    "    print(f\"Conectando ao MongoDB Atlas e carregando dados da coleção '{COLLECTION_NAME}'...\")\n",
    "    try:\n",
    "        client = MongoClient(MONGO_URI)\n",
    "        db = client[DB_NAME]\n",
    "        collection = db[COLLECTION_NAME]\n",
    "\n",
    "        # Busca todos os documentos da coleção e converte para DataFrame\n",
    "        cursor = collection.find({})\n",
    "        data = list(cursor)\n",
    "        client.close()\n",
    "\n",
    "        if not data:\n",
    "            print(\"AVISO: Nenhuma dado encontrado na coleção. Retornando DataFrame vazio.\")\n",
    "            df = pd.DataFrame()\n",
    "        else:\n",
    "            df = pd.DataFrame(data)\n",
    "            if '_id' in df.columns:\n",
    "                df.drop('_id', axis=1, inplace=True)\n",
    "            print(f\"Dados carregados com sucesso. Total de {len(df)} registros.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao conectar ou carregar dados do MongoDB: {e}\")\n",
    "        df = pd.DataFrame() # Retorna DataFrame vazio em caso de erro\n",
    "\n",
    "# Garante que o script não continue se o DataFrame estiver vazio\n",
    "if df.empty:\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c69603b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_inversa</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>horario</th>\n",
       "      <th>uf</th>\n",
       "      <th>municipio</th>\n",
       "      <th>tipo_acidente</th>\n",
       "      <th>condicao_metereologica</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>05:40:00</td>\n",
       "      <td>PA</td>\n",
       "      <td>SAO FRANCISCO DO PARA</td>\n",
       "      <td>Saida de leito carrocavel</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>-1,3101929</td>\n",
       "      <td>-47,74456398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>MG</td>\n",
       "      <td>UBERABA</td>\n",
       "      <td>Colisao transversal</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>-19,76747537</td>\n",
       "      <td>-47,98725511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>BA</td>\n",
       "      <td>CANUDOS</td>\n",
       "      <td>Saida de leito carrocavel</td>\n",
       "      <td>Nublado</td>\n",
       "      <td>-10,32002103</td>\n",
       "      <td>-39,06425211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>10:08:00</td>\n",
       "      <td>SP</td>\n",
       "      <td>APARECIDA</td>\n",
       "      <td>Colisao traseira</td>\n",
       "      <td>Sol</td>\n",
       "      <td>-22,85651665</td>\n",
       "      <td>-45,23114328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>12:10:00</td>\n",
       "      <td>MG</td>\n",
       "      <td>JUATUBA</td>\n",
       "      <td>Saida de leito carrocavel</td>\n",
       "      <td>Ceu Claro</td>\n",
       "      <td>-19,947864</td>\n",
       "      <td>-44,381226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_inversa    dia_semana   horario  uf              municipio  \\\n",
       "0   01/01/2020  quarta-feira  05:40:00  PA  SAO FRANCISCO DO PARA   \n",
       "1   01/01/2020  quarta-feira  06:00:00  MG                UBERABA   \n",
       "2   01/01/2020  quarta-feira  06:00:00  BA                CANUDOS   \n",
       "3   01/01/2020  quarta-feira  10:08:00  SP              APARECIDA   \n",
       "4   01/01/2020  quarta-feira  12:10:00  MG                JUATUBA   \n",
       "\n",
       "               tipo_acidente condicao_metereologica      latitude  \\\n",
       "0  Saida de leito carrocavel              Ceu Claro    -1,3101929   \n",
       "1        Colisao transversal              Ceu Claro  -19,76747537   \n",
       "2  Saida de leito carrocavel                Nublado  -10,32002103   \n",
       "3           Colisao traseira                    Sol  -22,85651665   \n",
       "4  Saida de leito carrocavel              Ceu Claro    -19,947864   \n",
       "\n",
       "      longitude  \n",
       "0  -47,74456398  \n",
       "1  -47,98725511  \n",
       "2  -39,06425211  \n",
       "3  -45,23114328  \n",
       "4    -44,381226  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13bb9c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        data  uf             municipio                tipo_acidente  \\\n",
      "0 2020-01-01  AL  MATRIZ DE CAMARAGIBE  Colisao com objeto estatico   \n",
      "1 2020-01-01  AL    UNIAO DOS PALMARES      Atropelamento de Animal   \n",
      "2 2020-01-01  AP        FERREIRA GOMES      Atropelamento de Animal   \n",
      "3 2020-01-01  AP          PORTO GRANDE    Saida de leito carrocavel   \n",
      "4 2020-01-01  BA               CANUDOS    Saida de leito carrocavel   \n",
      "\n",
      "  condicao_metereologica    dia_semana  acidentes  hora_media  \n",
      "0              Ceu Claro  quarta-feira          1         6.0  \n",
      "1                Nublado  quarta-feira          1         2.0  \n",
      "2              Ceu Claro  quarta-feira          1         0.0  \n",
      "3                  Chuva  quarta-feira          1        15.0  \n",
      "4                Nublado  quarta-feira          1         6.0  \n"
     ]
    }
   ],
   "source": [
    "df[\"data\"] = pd.to_datetime(df[\"data_inversa\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df[\"hora\"] = pd.to_datetime(df[\"horario\"], format=\"%H:%M:%S\", errors=\"coerce\").dt.hour\n",
    "\n",
    "# Remover nulos essenciais para a agregação\n",
    "df.dropna(subset=['data', 'hora', 'tipo_acidente', 'uf', 'municipio'], inplace=True)\n",
    "\n",
    "# AGREGACAO CORRIGIDA: Contar acidentes para a combinação única de Data, Local, Tipo e Condição\n",
    "cols_agrupamento = ['data', 'uf', 'municipio', 'tipo_acidente', 'condicao_metereologica', 'dia_semana']\n",
    "df_agg = df.groupby(cols_agrupamento).agg(\n",
    "    acidentes=(\"data\", \"count\"),\n",
    "    hora_media=('hora', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "print(df_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c708a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros agrupados: 371301\n"
     ]
    }
   ],
   "source": [
    "df_agg[\"dia_semana_num\"] = df_agg[\"data\"].dt.dayofweek\n",
    "df_agg[\"mes\"] = df_agg[\"data\"].dt.month\n",
    "df_agg[\"ano\"] = df_agg[\"data\"].dt.year\n",
    "df_agg[\"dia_do_ano\"] = df_agg[\"data\"].dt.dayofyear\n",
    "df_agg[\"dia_do_mes\"] = df_agg[\"data\"].dt.day\n",
    "\n",
    "print(f\"Total de registros agrupados: {len(df_agg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4056c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'label_encoder_mappings.json' atualizado.\n"
     ]
    }
   ],
   "source": [
    "cat_features = ['uf', 'municipio', 'tipo_acidente', 'condicao_metereologica']\n",
    "mappings = {}\n",
    "\n",
    "# Aplicar LabelEncoder e salvar mapeamento\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    df_agg[col] = le.fit_transform(df_agg[col].astype(str))\n",
    "    mappings[col] = list(le.classes_)\n",
    "    \n",
    "# Garantir sincronia do mapeamento para a interface.py\n",
    "with open('label_encoder_mappings.json', 'w', encoding='utf-8') as f:\n",
    "    mappings['dia_semana'] = sorted(df['dia_semana'].unique().tolist())\n",
    "    json.dump(mappings, f, ensure_ascii=False)\n",
    "print(\"'label_encoder_mappings.json' atualizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec018fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'uf', 'municipio', 'tipo_acidente', 'condicao_metereologica', \n",
    "    'hora_media', 'dia_semana_num', 'mes', 'ano', 'dia_do_ano', 'dia_do_mes'\n",
    "]\n",
    "\n",
    "X = df_agg[features]\n",
    "y = df_agg['acidentes']\n",
    "\n",
    "# Índices das colunas categóricas para o LightGBM (0 a 3)\n",
    "cat_indices = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a0cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada 1/10 -> R²: 0.4096 | RMSE: 0.1282\n",
      "Rodada 2/10 -> R²: 0.4104 | RMSE: 0.1282\n",
      "Rodada 3/10 -> R²: 0.4165 | RMSE: 0.1277\n",
      "Rodada 4/10 -> R²: 0.4016 | RMSE: 0.1333\n",
      "Rodada 5/10 -> R²: 0.4170 | RMSE: 0.1287\n",
      "Rodada 6/10 -> R²: 0.4294 | RMSE: 0.1286\n",
      "Rodada 7/10 -> R²: 0.4227 | RMSE: 0.1278\n",
      "Rodada 8/10 -> R²: 0.4222 | RMSE: 0.1322\n",
      "Rodada 9/10 -> R²: 0.4053 | RMSE: 0.1341\n",
      "Rodada 10/10 -> R²: 0.4153 | RMSE: 0.1334\n",
      "----------------------------------------\n",
      "MÉDIA FINAL -> R²: 0.4150 (±0.0080)\n",
      "MÉDIA FINAL -> RMSE: 0.1302\n"
     ]
    }
   ],
   "source": [
    "# Seleciona as features e o target\n",
    "r2_list = []\n",
    "rmse_list = []\n",
    "n_loops = 10\n",
    "\n",
    "for i in range(n_loops):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i*13)\n",
    "    \n",
    "    # --- HIPERPARÂMETROS EXTREMOS PARA MAXIMIZAR R² ---\n",
    "    # Foco: Aprender mais lentamente (LR baixo) e com mais profundidade\n",
    "    model = lgb.LGBMRegressor(\n",
    "        objective='poisson',       \n",
    "        n_estimators=3000,         # Aumento extremo no número de árvores\n",
    "        learning_rate=0.003,       # Diminuição drástica para precisão máxima\n",
    "        num_leaves=80,             # Aumento na complexidade da árvore\n",
    "        max_depth=15,              # Profundidade alta\n",
    "        min_child_samples=10,      # Permite explicar padrões de contagem muito pequena\n",
    "        reg_alpha=0.5,             # Aumento na regularização L1 (Lasso)\n",
    "        reg_lambda=0.5,            # Aumento na regularização L2 (Ridge)\n",
    "        subsample=0.8,             # Amostragem para reduzir variância\n",
    "        colsample_bytree=0.8,      # Amostragem para reduzir variância\n",
    "        random_state=i,\n",
    "        verbose=-1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, categorical_feature=cat_indices)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2_list.append(r2_score(y_test, y_pred))\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    print(f\"Rodada {i+1}/{n_loops} -> R²: {r2_list[-1]:.4f} | RMSE: {rmse_list[-1]:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"MÉDIA FINAL -> R²: {np.mean(r2_list):.4f} (±{np.std(r2_list):.4f})\")\n",
    "print(f\"MÉDIA FINAL -> RMSE: {np.mean(rmse_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee9d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final salvo em 'modelos\\preditor.pkl'. ✅\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pasta_modelos = Path('modelos')\n",
    "pasta_modelos.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define o caminho completo do arquivo\n",
    "caminho_arquivo = pasta_modelos / 'preditor.pkl'\n",
    "\n",
    "with open(caminho_arquivo, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Modelo final salvo em '{caminho_arquivo}'. ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
